{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHSoJH9SoRncBlfxNDunMo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swaroopkasaraneni/PythonProgramming/blob/main/cv.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Write a program to fetch hyperlinks from any website which user enters.\n"
      ],
      "metadata": {
        "id": "DM7v9tte8JzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def fetch_hyperlinks():\n",
        "    url = input(\"Enter the website URL (e.g., https://example.com): \")\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Check if the request was successful\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        hyperlinks = []\n",
        "        for link in soup.find_all('a', href=True):\n",
        "            hyperlinks.append(link['href'])\n",
        "\n",
        "        print(\"\\nHyperlinks found on the website:\")\n",
        "        for i, hyperlink in enumerate(hyperlinks, start=1):\n",
        "            print(f\"{i}: {hyperlink}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching the website: {e}\")\n",
        "\n",
        "fetch_hyperlinks()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7wK2sYY9RJY",
        "outputId": "d0c38856-a060-4a93-91a2-69aab49b9cdd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the website URL (e.g., https://example.com): https://www.google.com/\n",
            "\n",
            "Hyperlinks found on the website:\n",
            "1: https://www.google.com/imghp?hl=en&tab=wi\n",
            "2: https://maps.google.com/maps?hl=en&tab=wl\n",
            "3: https://play.google.com/?hl=en&tab=w8\n",
            "4: https://www.youtube.com/?tab=w1\n",
            "5: https://news.google.com/?tab=wn\n",
            "6: https://mail.google.com/mail/?tab=wm\n",
            "7: https://drive.google.com/?tab=wo\n",
            "8: https://www.google.com/intl/en/about/products?tab=wh\n",
            "9: http://www.google.com/history/optout?hl=en\n",
            "10: /preferences?hl=en\n",
            "11: https://accounts.google.com/ServiceLogin?hl=en&passive=true&continue=https://www.google.com/&ec=GAZAAQ\n",
            "12: /advanced_search?hl=en&authuser=0\n",
            "13: /intl/en/ads/\n",
            "14: /services/\n",
            "15: /intl/en/about.html\n",
            "16: /intl/en/policies/privacy/\n",
            "17: /intl/en/policies/terms/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Write  a  program  to  download  all  the  videos  from  youtube.com    for  django  from the hyperlink given belowhttps://www.youtube.com/playlist?list=PLxxA5z-8B2xk4szCgFmgonNcCboyNneMD"
      ],
      "metadata": {
        "id": "LB4odLGT8NPn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytube"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX34vQODLZOx",
        "outputId": "a62f2c31-c389-459f-8f76-332faebabda1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import Playlist, YouTube\n",
        "\n",
        "def download_youtube_playlist(playlist_url):\n",
        "    try:\n",
        "\n",
        "        playlist = Playlist(playlist_url)\n",
        "        print(f\"Downloading playlist: {playlist.title}\")\n",
        "        print(f\"Number of videos in playlist: {len(playlist.video_urls)}\")\n",
        "\n",
        "        for video_url in playlist.video_urls:\n",
        "            try:\n",
        "\n",
        "                video = YouTube(video_url)\n",
        "                stream = video.streams.get_lowest_resolution\n",
        "                print(f\"Downloading video: {video.title}\")\n",
        "                stream.download()\n",
        "                print(f\"Downloaded: {video.title}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to download video {video_url}: {e}\")\n",
        "\n",
        "        print(\"Playlist download completed!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# URL of the playlist\n",
        "playlist_url = \"https://www.youtube.com/playlist?list=PLxxA5z-8B2xk4szCgFmgonNcCboyNneMD\"\n",
        "\n",
        "# Call the function\n",
        "download_youtube_playlist(playlist_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "Vmq7LzxiLOt2",
        "outputId": "d197ab98-0439-4dd8-9a8b-a700c86422bb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading playlist: Python Django Tutorials\n",
            "Number of videos in playlist: 34\n",
            "Failed to download video https://www.youtube.com/watch?v=oT1A1KKf0SI: HTTP Error 403: Forbidden\n",
            "Failed to download video https://www.youtube.com/watch?v=fbJgeJjA7Cg: HTTP Error 403: Forbidden\n",
            "Failed to download video https://www.youtube.com/watch?v=7qiq8gnSrxg: HTTP Error 403: Forbidden\n",
            "Failed to download video https://www.youtube.com/watch?v=cF8WBg_S-qA: HTTP Error 403: Forbidden\n",
            "Failed to download video https://www.youtube.com/watch?v=TVuLEvsOVsw: HTTP Error 403: Forbidden\n",
            "Failed to download video https://www.youtube.com/watch?v=kvFDV1oM-ZA: HTTP Error 403: Forbidden\n",
            "Failed to download video https://www.youtube.com/watch?v=iA918NEFZxs: HTTP Error 403: Forbidden\n",
            "Failed to download video https://www.youtube.com/watch?v=3Dgfp6hLznA: HTTP Error 403: Forbidden\n",
            "Failed to download video https://www.youtube.com/watch?v=U_dDY7TvJ4E: HTTP Error 403: Forbidden\n",
            "Failed to download video https://www.youtube.com/watch?v=CFypO_LNmcc: HTTP Error 403: Forbidden\n",
            "Failed to download video https://www.youtube.com/watch?v=Tam4IGrPESg: HTTP Error 403: Forbidden\n",
            "Failed to download video https://www.youtube.com/watch?v=xaPHSlTmg1s: HTTP Error 403: Forbidden\n",
            "Failed to download video https://www.youtube.com/watch?v=gQe_8Q4YUpg: HTTP Error 403: Forbidden\n",
            "Failed to download video https://www.youtube.com/watch?v=T1PLT7JsRz0: HTTP Error 403: Forbidden\n",
            "Failed to download video https://www.youtube.com/watch?v=b43JIn-OGZU: HTTP Error 403: Forbidden\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-acb4af3a5e17>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Call the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mdownload_youtube_playlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplaylist_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-acb4af3a5e17>\u001b[0m in \u001b[0;36mdownload_youtube_playlist\u001b[0;34m(playlist_url)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0;31m# Get the highest resolution stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstreams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_highest_resolution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0;31m# Download the video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/__main__.py\u001b[0m in \u001b[0;36mstreams\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;32mclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mStreamQuery\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mStreamQuery\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \"\"\"\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_availability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mStreamQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmt_streams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/__main__.py\u001b[0m in \u001b[0;36mcheck_availability\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0motherwise\u001b[0m \u001b[0mdoes\u001b[0m \u001b[0mnothing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \"\"\"\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayability_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch_html\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/__main__.py\u001b[0m in \u001b[0;36mwatch_html\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_watch_html\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_watch_html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_watch_html\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_watch_html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytube/request.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, extra_headers, timeout)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mextra_headers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextra_headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_chunked\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_chunk_left\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mchunk_left\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_get_chunk_left\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    564\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# toss the CRLF at the end of the chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m                 \u001b[0mchunk_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_read_next_chunk_size\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_next_chunk_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;31m# Read the next chunk size from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chunk size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1303\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Create a csv file with name and hyperlink after fetching it from the web pagehttp://bioguide.congress.gov/biosearch/biosearch1.aspdownload the page source and save in html file and then perform scrapping"
      ],
      "metadata": {
        "id": "t--S7U258QKC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiD5dVB2NQu6",
        "outputId": "eb939eda-558b-4e20-d331-d4bbb1e51836"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "try:\n",
        "    url=\"http://bioguide.congress.gov/biosearch/biosearch1.aspdownload\"\n",
        "    response = requests.get(url)\n",
        "\n",
        "    html_file = \"bioguide.html\"\n",
        "    with open(html_file, \"w\", encoding=\"utf-8\") as file:\n",
        "        print(response.text)\n",
        "        file.write(response.text)\n",
        "        print(\"Webpage successfully downloaded and saved as 'bioguide.html'.\")\n",
        "\n",
        "    with open(html_file, 'r', encoding=\"utf-8\") as file:\n",
        "      soup = BeautifulSoup(file, 'html.parser')\n",
        "\n",
        "    data = []\n",
        "    for link in soup.find_all('a', href=True):\n",
        "        name = link.text.strip()\n",
        "        url = link['href']\n",
        "        if name:\n",
        "            full_url = f\"http://bioguide.congress.gov/biosearch/{url}\" if not url.startswith(\"http\") else url\n",
        "            data.append({\"Name\": name, \"Hyperlink\": full_url})\n",
        "    csv_file = \"Hyperlink.csv\"\n",
        "    with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=[\"Name\", \"Hyperlink\"])\n",
        "        writer.writeheader()\n",
        "        writer.writerows(data)\n",
        "\n",
        "    print(f\"Data has been written to {csv_file}\")\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Error fetching the website: {e}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv_WLsQaNRmc",
        "outputId": "17e5add6-fb65-4eb9-b387-56a71adabbf4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<!DOCTYPE html><html lang=\"en-US\"><head><title>Just a moment...</title><meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"><meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\"><meta name=\"robots\" content=\"noindex,nofollow\"><meta name=\"viewport\" content=\"width=device-width,initial-scale=1\"><style>*{box-sizing:border-box;margin:0;padding:0}html{line-height:1.15;-webkit-text-size-adjust:100%;color:#313131;font-family:system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol,Noto Color Emoji}body{display:flex;flex-direction:column;height:100vh;min-height:100vh}.main-content{margin:8rem auto;max-width:60rem;padding-left:1.5rem}@media (width <= 720px){.main-content{margin-top:4rem}}.h2{font-size:1.5rem;font-weight:500;line-height:2.25rem}@media (width <= 720px){.h2{font-size:1.25rem;line-height:1.5rem}}#challenge-error-text{background-image:url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzMiIgaGVpZ2h0PSIzMiIgZmlsbD0ibm9uZSI+PHBhdGggZmlsbD0iI0IyMEYwMyIgZD0iTTE2IDNhMTMgMTMgMCAxIDAgMTMgMTNBMTMuMDE1IDEzLjAxNSAwIDAgMCAxNiAzbTAgMjRhMTEgMTEgMCAxIDEgMTEtMTEgMTEuMDEgMTEuMDEgMCAwIDEtMTEgMTEiLz48cGF0aCBmaWxsPSIjQjIwRjAzIiBkPSJNMTcuMDM4IDE4LjYxNUgxNC44N0wxNC41NjMgOS41aDIuNzgzem0tMS4wODQgMS40MjdxLjY2IDAgMS4wNTcuMzg4LjQwNy4zODkuNDA3Ljk5NCAwIC41OTYtLjQwNy45ODQtLjM5Ny4zOS0xLjA1Ny4zODktLjY1IDAtMS4wNTYtLjM4OS0uMzk4LS4zODktLjM5OC0uOTg0IDAtLjU5Ny4zOTgtLjk4NS40MDYtLjM5NyAxLjA1Ni0uMzk3Ii8+PC9zdmc+);background-repeat:no-repeat;background-size:contain;padding-left:34px}@media (prefers-color-scheme:dark){body{background-color:#222;color:#d9d9d9}}</style><meta http-equiv=\"refresh\" content=\"390\"></head><body class=\"no-js\"><div class=\"main-wrapper\" role=\"main\"><div class=\"main-content\"><noscript><div class=\"h2\"><span id=\"challenge-error-text\">Enable JavaScript and cookies to continue</span></div></noscript></div></div><script>(function(){window._cf_chl_opt={cvId: '3',cZone: \"bioguide.congress.gov\",cType: 'managed',cRay: '8ede6d556ad2b087',cH: '7pgKszJQf94mCnEfSCYJJbdne8zKMJ9t3XZNpTfSrKM-1733510664-1.2.1.1-j0UpNWxDLMXkW2bZKnxZVOxNhe.N159cS4JsQNwsP.qxF_2SK9bOB_h1sSXpsj4o',cUPMDTk: \"\\/search?__cf_chl_tk=WdoBSuigECDwg5GRtqiNSA1KRJv8dS5IqkutEKpwqgQ-1733510664-1.0.1.1-aD9NzQ47NObA4CuN.reizlOPsebZOuhWiEKhK0oRnmA\",cFPWv: 'g',cITimeS: '1733510664',cTTimeMs: '1000',cMTimeMs: '390000',cTplC: 0,cTplV: 5,cTplB: 'cf',cK: \"\",fa: \"\\/search?__cf_chl_f_tk=WdoBSuigECDwg5GRtqiNSA1KRJv8dS5IqkutEKpwqgQ-1733510664-1.0.1.1-aD9NzQ47NObA4CuN.reizlOPsebZOuhWiEKhK0oRnmA\",md: \"Y5LIoo163q5iJb5mV4uBnLMDK6Bt3udW.5mavH3zPRw-1733510664-1.2.1.1-9fUd7G8UQiEwntSlvP4HS5nU_VFDPYrp2gZWnOeFnQe7k5hHxaor7UF4_quhBpmqjOZQYDSQSITIUxfjZ1ONyk4JfILBwylCPWTW5ibIdDhbIKXKJIBqO4g6LRxuxySqoiA3iMbJyusF_e.EvKU36KcCflvWCRqkZYJW9udD8gyFI5HlBSwTsCpJXQBfQikOA6fnpFVLzc9_J2yT8RmxqAJG7t85VB5fzTfGJefk7NBG81aWP816eIqh8RvKvZPtdkjAp29fpSJte1plNuxzKMJ.CEbed5u1g0e7Swb51A5T1em.ehw7BolcTug6x5ho4Pzm5rxEOQkqCM65mXZVM9h7KwFtbLopJb_.edUrVyfmax4R82LGxRkPR8yrrrbknoUlCw1_AvmdoLxGIj85T8LHrFTUEDyMk4HUX2dlL.gOdEMlo6O7pBTomaTStPVdh65a_McTB_qT0_xtUubcpOlMXCChIAE6DFArBr1ZhcnjjgF0J6BoFz7DTfWtD1LQh2m2xGjtTYjacoyFLGoAnOWD1RbXbJAYIshXXgwJAepj3KPShVhNPJtf.x31fN86K_MfTziAjlyakL6B85BWYi9eKJxa_CRhHlsoqGW3CxbPKPlpSyM0CR6bLD.2yrqkYZb6jOdvWzARhBdfeq4h0AiIl58mQxWMjRNILV_L2zehl5XDDD79vu0zo7aXHAmoIkC_lY3j_VN.WQsuUzVBJt1PlZg_F74Lx.kUrISP.O8DvI0WwPxqeVFiuxLZM2K70JIO6KlPdK3P4AI251shrkkOBzDVMm7KlNH4s94XHZKxMGE683VUu8AlWLpyv.Ksp1hMzZmBTQ1lzwQ2hcS32OkUh1i9W8OAtnBTrgbe9Ss4lwZacWu7kNcyUbN7V_44Q1NuwXE2SXnhsXVPocAdns4M5gMqKsIrnBDLId9UDcugCgq2EEWKpR8rjlGAnWpG_88J.h0mcpFQuLwIMKXZrFO8_67e7vbapJaifl2BeWkrpRhl.RjCZifjlpFW316lUOaOmQ_RQY8nQfSTdwW81YERD.YIusMYu0p5ZnrIlJ6paQ3G2CzMFbIZCAaMQ4EJIRHnA3Akk3obad1j9GFvXNWaHMM1Uc4JsH_aYZiMvzcBZ._JO3PvBW3RxUX.DW.UaOK8z_GGi0Ux9cklPQ9YOZH1FHPnwJcDAlOfIa._pfNlCYh1S3cCETwbW.DK_NEdf763h43NJ_RH8GHOn4vcZ_pVkaAd70d90TW.GVNowdYvLEYe.ym8Knt0hg8Xtx9Nb_7NQSXb990p2ERYuCeCbE10t1vlhIXBkKaoio9DNyDBKe5T69130uv720UbTM0y0OjoKnUHiBTCVV_O_6w.d2YOfAeJTeg6zHWGb6nDpbPRfCDpDl2hPrXq5C3O5nRVczKbPTha67leuh933ybcJq6lpucTdKSfiWDtopPdLf_FvHt.FN0FQSqahEZ4qHo7M3M4uBKrqu9TW_QF7Lfk900whwAnUdGHSSVfFRgeCXNNwzsLxFL.xmoOZgeeFAT7zQhLQ3HMSXxoFBP2yeYNUGzv6Q4o8Dz8UYXiF56GJv.JnH1F0MdNtAD.NkGtb_AlEupki.mjuu9rxSirlMOrcktCNox9rOK52txNSONeMdhTQ2U_ITACELSafnt0ttjaHIe.s0pVMHlxmqO8WfXCQnrR3BWuRKArXGqmnoTXMfoXkaVEw9jxH87pKBGluVml.xbQFjOrS7Zd_wZzOLAimrVdIiNS6DmJTTzMAUyGvOGydG4mdo8c7JWCCW6j53G60nSBOA4iJNwkeMNJzh.oXGgbetT02HSn7Ihx6wc8XgAk1dZjG4Nnd4RpgtqfIailWDf17qJKNe4y7EuIqkaSePEoSuKVTcOapJcFuzy6kaXkRJfFKGe63n2NcprdL2BWzdrZqShG9YsK6u5vGbs3N8cbvnsQm39mCHlBwk1WJq3DFpuDCK_vpheHiHAHgjm7ifeIwYMkZ3rGGqSIKXdIQqp2rMTZ9YhSm7BEzC_6w7bXVRJ5HnAy7Fj8PgTlQ_.gVG40Ifor05bqSK2mAFPInjXNW09P8emIKUAbQUr3Lcx0mlW_gsxLwpytNF.q9oVoaRw0H0SBrbx0Zx1RuCCm1kLZWPqoTNIKLPedx_hQ.MEnYnN38jcvFm6A3.HoVTlawPGbsA4TtNIv7O56gUefKQU.9ZZWHQwXvmFunFaY82Qsyt6m1Uhh1jB8j8dh.mTEs4mvnlRDITwlnZxwD7t.pA\",mdrd: \"tcuy98Dgnr2GONYAIY.ArqCKSi9kcYnyT1R6d9MoYWY-1733510664-1.2.1.1-nEIptij5LoNiRcC1AGNAEL7lYW43r_UdzTurISkz9Gl_EOXwcgupr9mZNAH01rawC4yEyMa9Iqmt9vU0H.VGDrOdYzDVeZJot3uNKC.SI7aHW.OK2bTWbODZ6ZmLoqP9kLBwv9g7lMcBCL7su8cG2k3UfZgX1wUH_EB0_EuuN2FBDKxxdeTnPVGbpMgN4yneOkuWLqj5jmvNJyrL1yAYDPhNK.A_T4DczWWqziUWONthsEyJHm_ABEpzzsyZJAaxJAxVRBV45UyWpmm33qRIDf1DfHmn63C64Y1xowNhU5.8WC8SXBeOT6S3aXbyLFSiWQLt9SJkS9ko.GKMFUAzRQVkTMCF98IMILHpfdc14qEBDIfrSe10Ll3x4jeaGASZcNUP7Mp2NoWJFd9qvy8yNTsSp2EF7TaKt4Q8JRgA1qUiGzxWUQwq2GlRcStZRNzj9QzpM3GegHYPeWTjbcY7izZ2DCMLZSmAIF.l9a9QulioB_wff_o_N3WO9WMLJRqdV8Ara.MqMeYgVdlVkkorSUGTuC99Ri6wEFlfl3A4JvrS0w1zwAK3yuZwxzvPukGau5Sew2fpinVxqIAHdCspgQ4W.wv8X_ptPTRyZ6ebOBtVrANedbEVsJac9TsQ7CKZeUC.Y.ts1wuZNEPsYPlDvQAZbpct3FuX8WDUbfChpGH2vaNwQSLyXV.o_U6DlEKURXVf8iSWriE1B82DgCnDuT927cdgMFd.5mtcXlOtdMsrPvquknocAw1_eWSbN7N4S2ZNKeiV9tPQpZ7oIZPVqWdNrFPNvQ.pjYVoB8EygzAiOoQDvq3radqTg3Z9fGp2Or3eOr4rLp9PP6MwU8D1naVJanbudmacNpNrBsuH_uj0TmgIg6KwokvT5s0GnVaEbkYwfDn343fkUAcluPpB_xecC60e7iG04NzmmvXf1PMQkNRHe8asEg1ZjEYsgehUlhr.Tujj1ROp9tl2wGt85a2j.j3Y_T4fgJMycsfIrCo.Fub4WGSndZ3jCG9euG7U55u2LgR2VXvCknN9KdKIAH5AXhBQvjwimgAuXY2H0RBma0FcB.BMoHxinBFuiFS1J82u5kOpTT7xszY1vgXR.7H4miS3hKxL8uWTcOZ3WWzZpySKAZuZ.ahiPkbGNt.AnmqQ1e5_yhCVXwIS5n9FBbmoMuREQrcS2vvGAiGtb6HOUMojYXP_J1zmFrXZE3uw_6pfTfkKaRhNU.oJdo3Fw5T1U0Ypu5EyDs7pVphfUxQJheGuocnHMqw4wiJWX91DEiXLEKTuF1uAkOr2M8Opa66enAQlTnw39PFWIddAxLqWRCuWG0OMAxT496yCR2FyCm2g7VJ8QXzSqGtR5j3L1Lm.SBh4Yvco9fNHzqzMZ1qwpCn4JYIidwbwS1iefa0xW_nrMY07yyUfmg8pURqNKm5SiSS_mz3bC6eMH9N5vZwR4wReCwA8CJ_ORebsz4OdvkUjaOXOGg.p1_2G1WZaZfQ7iZ5lZ4.zXJX08ADtcnvTwJTMMv.0H1UP97PRI.qeMbEBFBxJJkJaCRmZI._1sM2Dwzrrfo4pQVYl9OXcyC6kH9rFGVKY5BSNT6_Wi2p9LRaRVvtipKr5HZmpZJBWYVmMpLMDe4bOnkZmYnAD2MKGgngHlSO63PITeD9pvInxaBeub6WPWTwCtcnzeE0ABPfiZnY6QF4IvNPKrKeJbcFZplk.yEHxYUkLmJKDrMSNgs3dBMbL5gmQR1dIOvAdTfKlu7Lk1Hyb9xPL37M81Nz6pymsqcWTZGWvStFnh5qFTskqF1Qodn7TEY18l.N7U7zGlfnvX6LLQRvMSxT421HYPicydaI_Bt5WmjooO.ukwu.6vqbRSYYSvHZ.wOIlip8I00h7mo1K5kvjAyw6A6zwe6jHNZX0o60vk4DaRwr3cIEU6KFPoM1zmTHl49TvJHlD2GBbnwd5um4IRiTRhkIPwXKoK8cdLVZ60NHLG2i_KlCOR49IrpSxDq96pd66Gcl3zbWDgmLC9ZeP5Kz.lqP6jDAYYwjzz.EaMD9AsnoY9yh4.sUL2aTHDYoUYUZRz8BCX9sGCLokdQkwhHGqrrcwnMiXeuRGtJdwZQ7lGj9QoqZA.FGr1RYQKvpewkVu0V4lstGkZSStO2e63q0xFmPC04Nd03Mw2Hy3W2wluxqdklSqpINunwGRLo7oSEGx8w\"};var cpo = document.createElement('script');cpo.src = '/cdn-cgi/challenge-platform/h/g/orchestrate/chl_page/v1?ray=8ede6d556ad2b087';window._cf_chl_opt.cOgUHash = location.hash === '' && location.href.indexOf('#') !== -1 ? '#' : location.hash;window._cf_chl_opt.cOgUQuery = location.search === '' && location.href.slice(0, location.href.length - window._cf_chl_opt.cOgUHash.length).indexOf('?') !== -1 ? '?' : location.search;if (window.history && window.history.replaceState) {var ogU = location.pathname + window._cf_chl_opt.cOgUQuery + window._cf_chl_opt.cOgUHash;history.replaceState(null, null, \"\\/search?__cf_chl_rt_tk=WdoBSuigECDwg5GRtqiNSA1KRJv8dS5IqkutEKpwqgQ-1733510664-1.0.1.1-aD9NzQ47NObA4CuN.reizlOPsebZOuhWiEKhK0oRnmA\" + window._cf_chl_opt.cOgUHash);cpo.onload = function() {history.replaceState(null, null, ogU);}}document.getElementsByTagName('head')[0].appendChild(cpo);}());</script></body></html>\n",
            "Webpage successfully downloaded and saved as 'bioguide.html'.\n",
            "Data has been written to Hyperlink.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.from the question above, fetch only the hyperlinks5"
      ],
      "metadata": {
        "id": "ZIPBxGr48TG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "with open(\"bioguide.html\", \"r\", encoding=\"utf-8\") as file:\n",
        "    html_content = file.read()\n",
        "\n",
        "soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "hyperlinks = []\n",
        "for link in soup.find_all('a', href=True):\n",
        "    hyperlinks.append(link['href'])\n",
        "\n",
        "print(\"\\nHyperlinks found on the website:\")\n",
        "for i, hyperlink in enumerate(hyperlinks, start=1):\n",
        "    print(f\"{i}: {hyperlink}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Vfl2BdMT05Z",
        "outputId": "9d7fa074-fdba-4fb4-ad35-0cf7f93692d0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hyperlinks found on the website:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.from the question above, fetch -names, years, positions, parties, states, congress, fullLink"
      ],
      "metadata": {
        "id": "_JyowET88Vmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "with open(\"bioguide.html\", \"r\", encoding=\"utf-8\") as file:\n",
        "    html_content = file.read()\n",
        "\n",
        "soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "\n",
        "names = []\n",
        "years = []\n",
        "positions = []\n",
        "parties = []\n",
        "states = []\n",
        "congress = []\n",
        "full_links = []\n",
        "\n",
        "rows = soup.find_all(\"tr\")\n",
        "for row in rows[1:]:\n",
        "    cells = row.find_all(\"td\")\n",
        "    if len(cells) >= 6:\n",
        "        names.append(cells[0].text.strip())\n",
        "        years.append(cells[1].text.strip())\n",
        "        positions.append(cells[2].text.strip())\n",
        "        parties.append(cells[3].text.strip())\n",
        "        states.append(cells[4].text.strip())\n",
        "        congress.append(cells[5].text.strip())\n",
        "\n",
        "        link_tag = cells[0].find(\"a\")\n",
        "        full_links.append(link_tag[\"href\"].strip() if link_tag else \"N/A\")\n",
        "\n",
        "# Display the extracted data\n",
        "print(\"Names:\", names)\n",
        "print(\"Years:\", years)\n",
        "print(\"Positions:\", positions)\n",
        "print(\"Parties:\", parties)\n",
        "print(\"States:\", states)\n",
        "print(\"Congress:\", congress)\n",
        "print(\"Links:\", full_links)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ia0_2jtk8ada",
        "outputId": "0c29b26b-2f6b-4e12-bc3d-51c8bf1b493d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Names: []\n",
            "Years: []\n",
            "Positions: []\n",
            "Parties: []\n",
            "States: []\n",
            "Congress: []\n",
            "Links: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.Write Perform the web scrapping on the following page\n",
        "\n",
        "```\n",
        "<html>\n",
        "<head>\n",
        " <title>\n",
        " Page title\n",
        " </title>\n",
        "</head>\n",
        "<body>\n",
        " <p id=\"firstpara\" align=\"center\">\n",
        " This is paragraph\n",
        " <b>\n",
        " one\n",
        " </b>\n",
        " </p>\n",
        " <p id=\"secondpara\" align=\"blah\">\n",
        " This is paragraph\n",
        " <b>\n",
        " two\n",
        " </b>\n",
        " </p>\n",
        "</body>\n",
        "</html>\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "i) Read the page using BeautifulSoup and show it in well formatted indented\n",
        "manner.\n",
        "ii) Print the b tag from the page\n",
        "iii) Print all the tags that starts from b\n",
        "iv) Print text from the tags having 'title' and 'p'. by using lists\n",
        "v) Print text from the tags having 'title' and 'p'. by using dictionaries\n",
        "vi) Print all the tag names present in the page\n",
        "vii) Print the complete tag that have two, and only two, attributes\n",
        "viii) Print the tags that have one-character names and no attributes\n",
        "ix) Print all the tags which have a value of \"center\" for their \"align\" attribute\n",
        "x) From the xml content\n",
        "'<person name=\"Bob\"><parent rel=\"mother\" name=\"Alice\">'\n",
        "Print the attributes having \"name\" as \"Alice\"\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_s-dEDNM8b2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "html_content = \"\"\"\n",
        "<html>\n",
        "<head>\n",
        " <title>\n",
        " Page title\n",
        " </title>\n",
        "</head>\n",
        "<body>\n",
        " <p id=\"firstpara\" align=\"center\">\n",
        " This is paragraph\n",
        " <b>\n",
        " one\n",
        " </b>\n",
        " </p>\n",
        " <p id=\"secondpara\" align=\"blah\">\n",
        " This is paragraph\n",
        " <b>\n",
        " two\n",
        " </b>\n",
        " </p>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "###i) Parsing the HTML and Indented, formatted HTML\n",
        "print(\"\\nParsing the HTML and Indented, formatted:\")\n",
        "soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "print(soup.prettify())\n",
        "\n",
        "### ii) Print the <b> tag\n",
        "print(\"\\n<b> tag:\")\n",
        "print(soup.find('b'))\n",
        "\n",
        "### iii) Print all tags starting with \"b\"\n",
        "print(\"\\nAll tags starting with 'b':\")\n",
        "for tag in soup.find_all():\n",
        "    if tag.name.startswith('b'):\n",
        "        print(tag)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXJeg1WEVvYl",
        "outputId": "22aac1ea-3fb0-48dd-c16f-d7145a45be81"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Parsing the HTML and Indented, formatted:\n",
            "<html>\n",
            " <head>\n",
            "  <title>\n",
            "   Page title\n",
            "  </title>\n",
            " </head>\n",
            " <body>\n",
            "  <p align=\"center\" id=\"firstpara\">\n",
            "   This is paragraph\n",
            "   <b>\n",
            "    one\n",
            "   </b>\n",
            "  </p>\n",
            "  <p align=\"blah\" id=\"secondpara\">\n",
            "   This is paragraph\n",
            "   <b>\n",
            "    two\n",
            "   </b>\n",
            "  </p>\n",
            " </body>\n",
            "</html>\n",
            "\n",
            "\n",
            "<b> tag:\n",
            "<b>\n",
            " one\n",
            " </b>\n",
            "\n",
            "All tags starting with 'b':\n",
            "<body>\n",
            "<p align=\"center\" id=\"firstpara\">\n",
            " This is paragraph\n",
            " <b>\n",
            " one\n",
            " </b>\n",
            "</p>\n",
            "<p align=\"blah\" id=\"secondpara\">\n",
            " This is paragraph\n",
            " <b>\n",
            " two\n",
            " </b>\n",
            "</p>\n",
            "</body>\n",
            "<b>\n",
            " one\n",
            " </b>\n",
            "<b>\n",
            " two\n",
            " </b>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### iv) Text from 'title' and 'p' using lists\n",
        "print(\"\\nText from 'title' and 'p' (using lists):\")\n",
        "tags_list = soup.find_all(['title', 'p'])\n",
        "texts_list = [tag.get_text(strip=True) for tag in tags_list]\n",
        "print(texts_list)\n",
        "\n",
        "### v) Text from 'title' and 'p' using dictionaries\n",
        "print(\"\\nText from 'title' and 'p' (using dictionaries):\")\n",
        "texts_dict = {tag.name: tag.get_text(strip=True) for tag in tags_list}\n",
        "print(texts_dict)\n",
        "\n",
        "### vi) Print all tag names\n",
        "print(\"\\nAll tag names in the page:\")\n",
        "tag_names = {tag.name for tag in soup.find_all()}\n",
        "print(tag_names)\n",
        "\n",
        "### vii) Tags with exactly two attributes\n",
        "print(\"\\nTags with exactly two attributes:\")\n",
        "tags_with_two_attrs = [tag for tag in soup.find_all() if len(tag.attrs) == 2]\n",
        "print(tags_with_two_attrs)\n",
        "\n",
        "### viii) Tags with one-character names and no attributes\n",
        "print(\"\\nTags with one-character names and no attributes:\")\n",
        "tags_one_char_no_attrs = [\n",
        "    tag for tag in soup.find_all() if len(tag.name) == 1 and not tag.attrs\n",
        "]\n",
        "print(tags_one_char_no_attrs)\n",
        "\n",
        "### ix) Tags with 'align=center'\n",
        "print(\"\\nTags with align='center':\")\n",
        "tags_align_center = soup.find_all(attrs={'align': 'center'})\n",
        "print(tags_align_center)\n",
        "\n",
        "### x) Attributes with name='Alice' in XML\n",
        "xml_content='''<person name=\"Bob\"><parent rel=\"mother\" name=\"Alice\">'''\n",
        "print(\"\\nAttributes with name='Alice' in XML:\")\n",
        "xml_soup = BeautifulSoup(xml_content, 'xml')\n",
        "tags_with_name_alice = xml_soup.find_all(attrs={\"name\": \"Alice\"})\n",
        "print(tags_with_name_alice)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcBw3nkw89C_",
        "outputId": "26add052-8980-41e4-dff1-0c389e787070"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text from 'title' and 'p' (using lists):\n",
            "['Page title', 'This is paragraphone', 'This is paragraphtwo']\n",
            "\n",
            "Text from 'title' and 'p' (using dictionaries):\n",
            "{'title': 'Page title', 'p': 'This is paragraphtwo'}\n",
            "\n",
            "All tag names in the page:\n",
            "{'title', 'html', 'body', 'p', 'head', 'b'}\n",
            "\n",
            "Tags with exactly two attributes:\n",
            "[<p align=\"center\" id=\"firstpara\">\n",
            " This is paragraph\n",
            " <b>\n",
            " one\n",
            " </b>\n",
            "</p>, <p align=\"blah\" id=\"secondpara\">\n",
            " This is paragraph\n",
            " <b>\n",
            " two\n",
            " </b>\n",
            "</p>]\n",
            "\n",
            "Tags with one-character names and no attributes:\n",
            "[<b>\n",
            " one\n",
            " </b>, <b>\n",
            " two\n",
            " </b>]\n",
            "\n",
            "Tags with align='center':\n",
            "[<p align=\"center\" id=\"firstpara\">\n",
            " This is paragraph\n",
            " <b>\n",
            " one\n",
            " </b>\n",
            "</p>]\n",
            "\n",
            "Attributes with name='Alice' in XML:\n",
            "[<parent name=\"Alice\" rel=\"mother\"/>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PbAsNj3m8njQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}